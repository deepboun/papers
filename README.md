# Papers 
List of papers that we discuss during the sessions.


## Upcoming Papers
* Learning to learn by gradient descent by gradient descent, Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, Nando de Freitas, NIPS 2016

  **Presenter** : Arda Celebi

  **In short** : Optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way.

  **Paper** : https://arxiv.org/abs/1606.04474
  
  **Github** : https://github.com/deepmind/learning-to-learn
  
  **Date**: TBA

## Previous Papers
* (19/01/2017):scroll: **[Relation Extraction: Perspective from Convolutional Neural Networks](http://aclanthology.info/papers/relation-extraction-perspective-from-convolutional-neural-networks)**

  **Citation:** Thien Huu Nguyen and Ralph Grishman. 2015a. Relation extraction: Perspective from convolutional neural networks. In The NAACL Workshop on Vector Space Modeling for NLP (VSM).

  **One sentence from Abstract:** In this work, we depart from these traditional approaches with complicated feature engineering by introducing a convolutional neural network for relation extraction that automatically learns features from sentences and minimizes the dependence on external toolkits and resources. Our model takes advantages of multiple window sizes for filters and pre-trained word embeddings as an initializer on a non-static architecture to improve the performance. We emphasize the relation extraction problem with an unbalanced corpus.

  **Link:** http://aclanthology.info/papers/relation-extraction-perspective-from-convolutional-neural-networks
  
  **More info:** [Implementation](https://github.com/hadyelsahar/CNN-RelationExtraction) 

* (19/01/2017)


